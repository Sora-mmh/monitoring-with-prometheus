{"annotations":{"description":"CPU load on host is over 50% Value = 85.24444444444472\n Instance = \n","summary":"Host CPU load high"},"endsAt":"2025-08-06T21:05:49.196Z","fingerprint":"a46255e0c6346e78","receivers":[{"name":"monitoring/main-rules-alert-config/email"}],"startsAt":"2025-08-06T21:01:49.196Z","status":{"inhibitedBy":[],"mutedBy":[],"silencedBy":[],"state":"active"},"updatedAt":"2025-08-06T21:01:49.201Z","generatorURL":"http://monitoring-kube-prometheus-prometheus.monitoring:9090/graph?g0.expr=100+-+%28avg+by+%28instance%29+%28rate%28node_cpu_seconds_total%7Bmode%3D%22idle%22%7D%5B2m%5D%29%29+%2A+100%29+%3E+50\u0026g0.tab=1","labels":{"alertname":"HostHighCpuLoad","instance":"192.168.11.142:9100","namespace":"monitoring","prometheus":"monitoring/monitoring-kube-prometheus-prometheus","severity":"warning"}}

{"annotations":{"description":"Pod cpu-stress-test is crash looping\n Value = 6","summary":"Kubernetes pod crash looping"},"endsAt":"2025-08-06T21:18:19.196Z","fingerprint":"6f4bcf388b3d8d79","receivers":[{"name":"monitoring/main-rules-alert-config/email"}],"startsAt":"2025-08-06T21:11:19.196Z","status":{"inhibitedBy":[],"mutedBy":[],"silencedBy":[],"state":"active"},"updatedAt":"2025-08-06T21:14:19.199Z","generatorURL":"http://monitoring-kube-prometheus-prometheus.monitoring:9090/graph?g0.expr=kube_pod_container_status_restarts_total+%3E+5\u0026g0.tab=1","labels":{"alertname":"KubernetesPodCrashLooping","container":"cpu-stress-test","endpoint":"http","instance":"192.168.34.33:8080","job":"kube-state-metrics","namespace":"monitoring","pod":"cpu-stress-test","prometheus":"monitoring/monitoring-kube-prometheus-prometheus","service":"monitoring-kube-state-metrics","severity":"critical","uid":"f7d8b43e-9284-4c23-80e1-9db6b9cfe866"}}